system:
  name: queenbee
  version: 1.0.0
  environment: development

database:
  host: ${DB_HOST:localhost}
  port: ${DB_PORT:5432}
  name: ${DB_NAME:queenbee}
  user: ${DB_USER:queenbee}
  password: ${DB_PASSWORD}
  ssl_mode: ${DB_SSL_MODE:prefer}

ollama:
  host: ${OLLAMA_HOST:http://localhost:11434}
  model: gpt-oss:20b
  timeout: 300

openrouter:
  api_key: ${OPENROUTER_API_KEY:}
  model: openai/gpt-oss-20b:free
  timeout: 300
  base_url: https://openrouter.ai/api/v1
  verify_ssl: false  # Disable SSL verification (for testing with corporate proxies)

agents:
  ttl:
    idle_timeout_minutes: 10
    check_interval_seconds: 30
  
  max_concurrent_specialists: 10
  
  queen:
    system_prompt_file: ./prompts/queen.md
    complexity_threshold: auto
  
  divergent:
    system_prompt_file: ./prompts/divergent.md
    max_iterations: 25
    max_tokens: 500  # Maximum tokens per contribution
  
  convergent:
    system_prompt_file: ./prompts/convergent.md
    max_iterations: 25
    max_tokens: 500  # Maximum tokens per contribution
  
  critical:
    system_prompt_file: ./prompts/critical.md
    max_iterations: 25
    max_tokens: 500  # Maximum tokens per contribution
  
  summarizer:
    system_prompt_file: ./prompts/summarizer.md
    max_iterations: 25
    max_tokens: 0  # No limit for summarizer

consensus:
  max_rounds: 20
  agreement_threshold: "all"
  discussion_rounds: 20  # Number of rounds for iterative agent discussion
  specialist_timeout_seconds: 300  # Maximum wait time for specialists (5 minutes)

logging:
  level: ${LOG_LEVEL:INFO}
  format: json
  output: stdout
